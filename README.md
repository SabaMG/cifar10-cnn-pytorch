# ğŸ§  CIFAR-10 Image Classification (ResNet-18 + PyTorch)

This project implements a deep learning pipeline to classify CIFAR-10 images using PyTorch, progressively improving from a basic CNN to a ResNet-18 backbone.

> ğŸš€ Current version: **v3.0**
> ğŸ¯ Final test accuracy: **90.99%** (ResNet-18, label smoothing, early stopping, LR scheduler, MPS support)

---

## ğŸš€ Features

- âœ… ResNet-18 backbone for high-accuracy image classification
- âœ… Modular codebase: model, data, training, evaluation, config
- âœ… Training reproducibility with fixed random seeds
- âœ… `AdamW` optimizer with `StepLR` scheduler
- âœ… Label Smoothing via `CrossEntropyLoss(label_smoothing=0.1)`
- âœ… Best model saving during training (`best_model.pth`)
- âœ… TensorBoard logging: loss, accuracy, learning rate, weight histograms
- âœ… MPS support for Apple Silicon (macOS)

---

## ğŸ§ª Quickstart

### 1. Clone and create virtual environment

```bash
git clone https://github.com/SabaMG/cifar10-cnn-pytorch.git
cd cifar10-cnn-pytorch
python3 -m venv .venv
source .venv/bin/activate
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. Train the model

```bash
python main.py
```

The best model will be saved automatically as `best_model.pth`.

### 4. Launch TensorBoard (optional)

```bash
tensorboard --logdir=runs
```

---

## ğŸ§  Model Versions

| Version | Architecture     | Description                             | Accuracy   |
|---------|------------------|-----------------------------------------|------------|
| v1.0    | Basic CNN (3 conv) | Lightweight, easy to train              | 81.43%     |
| v2.0    | Deep CNN (6 conv) | Larger capacity, dropout, batchnorm     | 87.43%     |
| v3.0    | ResNet-18         | Deeper pretrained-style model, stable   | **90.99%** |

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ dataset.py           # CIFAR-10 loading and transforms
â”œâ”€â”€ model.py             # ResNet-18 model definition
â”œâ”€â”€ train.py             # Training loop (TensorBoard, checkpoint, early stop)
â”œâ”€â”€ evaluate.py          # Evaluation logic
â”œâ”€â”€ main.py              # Main entrypoint
â”œâ”€â”€ utils.py             # Helpers (set_seed, etc.)
â”œâ”€â”€ config.py            # Device config
â”œâ”€â”€ best_model.pth       # Best model (autogenerated)
â”œâ”€â”€ runs/                # TensorBoard logs
â”œâ”€â”€ requirements.txt     # Dependencies
â””â”€â”€ README.md
```

---

## ğŸ“Œ Notes

- Trained on Apple Silicon (MPS backend), supports CPU/GPU as well
- `train.py` supports early stopping, checkpointing, and logging by default
- Model performance is logged with TensorBoard after every epoch

---

## ğŸªª License

MIT License